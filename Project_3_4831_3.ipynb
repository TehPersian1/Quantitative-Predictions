{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff38565d",
   "metadata": {},
   "source": [
    "# CPSC 483-02 Project 3 Fall 2021\n",
    "\n",
    "By Shervin Afrasiabi | shervina@csu.fullerton.edu \n",
    "\n",
    "Yesh Patel | yesh@csu.fullerton.edu\n",
    "\n",
    "Vishva Patel | Vishva360@csu.fullerton.edu\n",
    "\n",
    "### Due November 19th 2021 @ 9:45 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a48f9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #1\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt \n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "data = []\n",
    "data = pd.read_csv('bank-additional-full.csv', delimiter = ';')\n",
    "data.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab863c2",
   "metadata": {},
   "source": [
    "# 1\n",
    "\n",
    "In the cell above we opened the bank additional csv and examined a few entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e11622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #2\n",
    "X = data[data.columns[0:19]]\n",
    "y = data[data.columns[20]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.10, random_state = (2021-10-25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83426e6e",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "We separate the training and test sets in the cell block above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77986584",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"duration\"]) #3\n",
    "X_test = X_test.drop(columns = [\"duration\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef35a6",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "We dropped the duration columns based on the project description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fb80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainCategorical = X_train[X_train.columns[0:6]]\n",
    "X_testCategorical = X_test[X_test.columns[0:6]] \n",
    "\n",
    "X_trainCategorical = pd.get_dummies(X_trainCategorical, drop_first = True) #4\n",
    "X_testCategorical = pd.get_dummies(X_testCategorical, drop_first = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f227b95",
   "metadata": {},
   "source": [
    "# 4 \n",
    "\n",
    "In the cells above we isolate the bank client data. We then encode them with pd.get_dummies()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747e85c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.8818419703795625\n",
      "Test score:  0.8786113134255887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB #5\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_trainCategorical, y_train)\n",
    "trainScore = cnb.score(X_trainCategorical, y_train)\n",
    "testScore = cnb.score(X_testCategorical, y_test)\n",
    "print(\"Train score: \",trainScore)\n",
    "print(\"Test score: \",testScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5c226",
   "metadata": {},
   "source": [
    "# 5 \n",
    "\n",
    "According to our results, the score is relatively accurate about 88%, but it could be better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0234a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  17  Max:  98\n"
     ]
    }
   ],
   "source": [
    "ageList = X_train[X_train.columns[0]] #6\n",
    "\n",
    "print(\"Min: \",ageList.min(),\" Max: \",ageList.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896b83c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b31a3d2c",
   "metadata": {},
   "source": [
    "# 6\n",
    "\n",
    "\n",
    "Minimum age: 17\n",
    "Maximum age: 98\n",
    "The age range provides 81 categories #reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb00e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned Training Score:  0.8824354581995738\n",
      "Binned Test Score:  0.8805535324107793\n"
     ]
    }
   ],
   "source": [
    "bins = [10,20,30,40,50,60,70,80,90] #7\n",
    "TestBinnedData = X_testCategorical.copy(deep = True)\n",
    "TrainedBinnedData = X_trainCategorical.copy(deep = True)\n",
    "\n",
    "cnb_binned = CategoricalNB()\n",
    "\n",
    "TrainedBinnedData['binned'] = pd.cut(X_train['age'],bins)\n",
    "TrainedBinnedData = TrainedBinnedData.drop('age', axis = 1)\n",
    "TrainedBinnedData = pd.get_dummies(TrainedBinnedData, drop_first = True) \n",
    "cnb_binned.fit(TrainedBinnedData, y_train)\n",
    "\n",
    "\n",
    "TestBinnedData['binned'] = pd.cut(X_test['age'],bins)\n",
    "TestBinnedData = TestBinnedData.drop('age', axis = 1)\n",
    "TestBinnedData = pd.get_dummies(TestBinnedData, drop_first = True) \n",
    "cnb_binned.fit(TestBinnedData, y_test)\n",
    "\n",
    "\n",
    "BinnedTrainScore = cnb_binned.score(TrainedBinnedData, y_train)\n",
    "BinnedTestScore = cnb_binned.score(TestBinnedData, y_test)\n",
    "\n",
    "print(\"Binned Training Score: \",BinnedTrainScore)\n",
    "print(\"Binned Test Score: \",BinnedTestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fcb374",
   "metadata": {},
   "source": [
    "# 7 \n",
    "\n",
    "The score's improvement was negligable, the results are almost the exact same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c983adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbor Training Score:  0.8883163829615042\n",
      "KNeighbor Test Score:  0.8926924010682205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import *     #8\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_trainCategorical, y_train)\n",
    "KNeighborsTrainScore = knn.score(X_trainCategorical, y_train)\n",
    "\n",
    "knn.fit(X_testCategorical, y_test)\n",
    "KNeighborsTestScore = knn.score(X_testCategorical, y_test)\n",
    "print(\"KNeighbor Training Score: \",KNeighborsTrainScore)\n",
    "print(\"KNeighbor Test Score: \",KNeighborsTestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05a2b0",
   "metadata": {},
   "source": [
    "# 8\n",
    "\n",
    "Our test score was higher compared to experiment 5, but the improvements were quite negligable(<1%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc51ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Count:  473  No Count:  3646\n"
     ]
    }
   ],
   "source": [
    "yesCount = 0 #9\n",
    "noCount = 0\n",
    "\n",
    "for result in y_test: \n",
    "    if(result == \"no\"):\n",
    "        noCount+= 1\n",
    "    else:\n",
    "        yesCount+= 1\n",
    "print(\"Yes Count: \", yesCount,\" No Count: \", noCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc025b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3646    0]\n",
      " [ 473    0]] 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score #10\n",
    "y_test.replace(('yes', 'no'),(1,0), inplace = True)\n",
    "y_testzeros = np.zeros_like(y_test)\n",
    "testConfusionMatrix = confusion_matrix(y_test, y_testzeros)\n",
    "testRocScore = roc_auc_score(y_test, y_testzeros)\n",
    "print(testConfusionMatrix, testRocScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f4a46",
   "metadata": {},
   "source": [
    "# 9\n",
    "\n",
    "3646 No \n",
    "\n",
    "473 Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3d109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binned\n",
      " [[3569   77]\n",
      " [ 415   58]] 0.5507512649618047\n",
      "knn\n",
      " [[3607   39]\n",
      " [ 403   70]] 0.5686474447365644\n"
     ]
    }
   ],
   "source": [
    "#10/11 \n",
    "y_testbins = cnb_binned.predict(TestBinnedData)\n",
    "y_testbins = pd.DataFrame(y_testbins)\n",
    "y_testbins.replace(('yes','no'),(1,0), inplace = True)\n",
    "\n",
    "testConfusionMatrixbins = confusion_matrix(y_test, y_testbins)\n",
    "testRocScorebins = roc_auc_score(y_test, y_testbins)\n",
    "print(\"binned\\n\",testConfusionMatrixbins, testRocScorebins)\n",
    "\n",
    "\n",
    "y_testknn = knn.predict(X_testCategorical)\n",
    "y_testknn = pd.DataFrame(y_testknn)\n",
    "y_testknn.replace(('yes','no'),(1,0), inplace = True)\n",
    "            \n",
    "\n",
    "testConfusionMatrixknn = confusion_matrix(y_test, y_testknn)\n",
    "testRocScoreknn = roc_auc_score(y_test, y_testknn)\n",
    "print(\"knn\\n\",testConfusionMatrixknn, testRocScoreknn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e5f1e",
   "metadata": {},
   "source": [
    "# 10 & 11\n",
    "\n",
    "Based on our results above, even though our score is lower, it appears that we are correctly predicting a majority of the results based on our confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "763226ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted = data[data.columns[20]] #12\n",
    "weighted = weighted.where(weighted == 'yes')\n",
    "weighted.replace(('yes'),(1), inplace = True)\n",
    "data_sampled = data.sample(frac = 1, replace = True, weights = weighted, random_state = (2021-10-25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37772cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Balanced Naive Bayes:  0.6241358600508581\n",
      "Balanced bayes\n",
      " [[15789 17113]\n",
      " [12301 33054]]\n",
      "Balanced bayes auc:  0.6043318398080197\n"
     ]
    }
   ],
   "source": [
    "data_sampled_x = data_sampled[data_sampled.columns[0:6]]\n",
    "data_sampled_y = data_sampled[data_sampled.columns[20]]\n",
    "data_sampled_x_categorical = pd.get_dummies(data_sampled_x, drop_first = True)\n",
    "X_trainCategorical_sampled = X_trainCategorical.drop('default_yes', axis = 1)\n",
    "\n",
    "\n",
    "balanced_data_x = pd.concat([X_trainCategorical_sampled, data_sampled_x_categorical])\n",
    "balanced_data_y = pd.concat([y_train, data_sampled_y])\n",
    "\n",
    "balanced_data_y.replace(('yes', 'no'),(1,0), inplace = True)\n",
    "\n",
    "cnb_balanced = CategoricalNB()\n",
    "cnb_balanced.fit(balanced_data_x, balanced_data_y)\n",
    "cnb_balanced_trainScore = cnb_balanced.score(balanced_data_x, balanced_data_y)\n",
    "print(\"Categorical Balanced Naive Bayes: \", cnb_balanced_trainScore)\n",
    "\n",
    "bayes_bins = cnb_balanced.predict(balanced_data_x)\n",
    "bayes_bins = pd.DataFrame(bayes_bins)\n",
    "bayes_bins.replace(('yes','no'),(1,0), inplace = True)\n",
    "\n",
    "bayesConfusionMatrixbins = confusion_matrix(balanced_data_y, bayes_bins)\n",
    "bayesRocScorebins = roc_auc_score(balanced_data_y, bayes_bins)\n",
    "print(\"Balanced bayes\\n\",bayesConfusionMatrixbins)\n",
    "print(\"Balanced bayes auc: \", bayesRocScorebins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9497f",
   "metadata": {},
   "source": [
    "# 12\n",
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478829b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn 0.75997035408973\n",
      "knn_balanced\n",
      " [[20325 12577]\n",
      " [ 6207 39148]]\n",
      "knn_balanced auc:  0.7404449462942773\n"
     ]
    }
   ],
   "source": [
    "knn_balanced = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_balanced.fit(balanced_data_x, balanced_data_y)\n",
    "KNeighborsTrainScore_balanced = knn_balanced.score(balanced_data_x, balanced_data_y)\n",
    "print(\"Knn\", KNeighborsTrainScore_balanced)\n",
    "\n",
    "balanced_knn = knn_balanced.predict(balanced_data_x)\n",
    "balanced_knn = pd.DataFrame(balanced_knn)\n",
    "balanced_knn.replace(('yes','no'),(1,0), inplace = True)\n",
    "\n",
    "ConfusionMatrixknn = confusion_matrix(balanced_data_y, balanced_knn)\n",
    "RocScoreknn = roc_auc_score(balanced_data_y, balanced_knn)\n",
    "print(\"knn_balanced\\n\",ConfusionMatrixknn)\n",
    "print(\"knn_balanced auc: \", RocScoreknn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2397ad42",
   "metadata": {},
   "source": [
    "# 13\n",
    "\n",
    "Based on the results of the experiment we can conclude that knn performs better on the balanced training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9469aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.7199816558310178\n",
      "test:  0.7193493566399611\n",
      "[[23717  9185]\n",
      " [ 1195  2972]] 0.7170302906069623\n",
      "[[2634 1012]\n",
      " [ 144  329]] 0.7089978997517046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_quan = data[data.columns[15:20]]\n",
    "y_quan = data[data.columns[20]]\n",
    "\n",
    "X_train_quan, X_test_quan, y_train_quan, y_test_quan = train_test_split(X_quan, y_quan, test_size=0.1, random_state= (2021-10-25))\n",
    "\n",
    "X_test_quan.head()\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_quan, y_train_quan)\n",
    "trainScore_quan = gnb.score(X_train_quan, y_train_quan)\n",
    "testScore_quan = gnb.score(X_test_quan, y_test_quan)\n",
    "print('train: ',trainScore_quan)\n",
    "print('test: ', testScore_quan)\n",
    "\n",
    "y_train_quan.replace(('yes', 'no'),(1,0), inplace = True)\n",
    "y_test_quan.replace(('yes', 'no'),(1,0), inplace = True)\n",
    "\n",
    "\n",
    "y_pred_train_quan = gnb.predict(X_train_quan)\n",
    "y_pred_train_quan = pd.DataFrame(y_pred_train_quan)\n",
    "y_pred_train_quan.replace(('yes','no'),(1,0), inplace = True)\n",
    "\n",
    "y_pred_test_quan = gnb.predict(X_test_quan)\n",
    "y_pred_test_quan = pd.DataFrame(y_pred_test_quan)\n",
    "y_pred_test_quan.replace(('yes','no'),(1,0), inplace = True)\n",
    "        \n",
    "ConfusionMatrix_train_quan = confusion_matrix(y_train_quan, y_pred_train_quan)\n",
    "RocScore_train_quan = roc_auc_score(y_train_quan, y_pred_train_quan)\n",
    "print(ConfusionMatrix_train_quan, RocScore_train_quan)\n",
    "        \n",
    "ConfusionMatrix_test_quan = confusion_matrix(y_test_quan, y_pred_test_quan)\n",
    "RocScore_test_quan = roc_auc_score(y_test_quan, y_pred_test_quan)\n",
    "print(ConfusionMatrix_test_quan, RocScore_test_quan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b31ed",
   "metadata": {},
   "source": [
    "# 14 \n",
    "\n",
    "Based on the score, confusion matrix, and AUC score, we can say that social and economic context attributes are able to better predict the data than the previous example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bb07ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Score:  0.7145814431935801\n",
      "gnb Confusion Matrix: \n",
      " [[23717  9185]\n",
      " [13151 32204]] \n",
      "gnb ROC score:  0.715440316603251\n"
     ]
    }
   ],
   "source": [
    "data_sampled_x = data_sampled[data_sampled.columns[15:20]]\n",
    "data_sampled_y = data_sampled[data_sampled.columns[20]]\n",
    "\n",
    "balanced_data_x_quan = pd.concat([X_train_quan, data_sampled_x])\n",
    "balanced_data_y_quan = pd.concat([y_train_quan, data_sampled_y])\n",
    "\n",
    "balanced_data_y_quan.replace(('yes', 'no'),(1,0), inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "gnb_balanced = GaussianNB()\n",
    "gnb_balanced.fit(balanced_data_x_quan, balanced_data_y_quan)\n",
    "gnb_balanced_trainScore = gnb_balanced.score(balanced_data_x_quan, balanced_data_y_quan)\n",
    "print(\"Gaussian Naive Bayes Score: \", gnb_balanced_trainScore)\n",
    "\n",
    "gnb_bins = gnb_balanced.predict(balanced_data_x_quan)\n",
    "gnb_bins = pd.DataFrame(gnb_bins)\n",
    "gnb_bins.replace(('yes','no'),(1,0), inplace = True)\n",
    "\n",
    "gnbConfusionMatrixbins = confusion_matrix(balanced_data_y_quan, gnb_bins)\n",
    "gnbRocScorebins = roc_auc_score(balanced_data_y_quan, gnb_bins)\n",
    "print(\"gnb Confusion Matrix: \\n\",gnbConfusionMatrixbins, \"\\ngnb ROC score: \",gnbRocScorebins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17a7da",
   "metadata": {},
   "source": [
    "# 15\n",
    "\n",
    "We were expecting the results of the experiment to change, however based on our results the balanced training set produced similar results to our previous experiment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
